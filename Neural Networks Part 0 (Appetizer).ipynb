{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Project II\n",
    "\n",
    "# Neural Networks (Introduction)\n",
    "\n",
    "Lecturer: Jan Bauer (jan.bauer@dhbw-mannheim.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### About me:\n",
    "\n",
    "-  Mathematics-Economics M.Sc (KÃ¸benhavns Universitet, 2017)\n",
    "-  Research Assistant (PhD Student) at the chair of Management (JGU Mainz, 2018)\n",
    "-  Research Assistant (PhD Student) at the chair of Application Management (DHBW, 2019)\n",
    "\n",
    "-  Research interests: (Time Series) Econometrics, Macroeconometrics & passion for everything statistic-ish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### About you:\n",
    "\n",
    "-  Solid background in calculus (derivatives)\n",
    "-  Python coding skills (presumably more than I have)\n",
    "-  Recap the lecture to not loose track\n",
    "-  Looking for typos (thank you)\n",
    "-  In-lecture-feedback (pace, difficulty,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Administrative Things\n",
    "\n",
    "-  Lecture times: 1-2 times a week (as regular as possible)\n",
    "-  Slides: Google Calendar\n",
    "-  10 lectures of 3h each\n",
    "-  Lecture 7(?): Paper\n",
    "-  Sources: Notes\n",
    "-  Questions? Email me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "-  Sources:\n",
    "    - Neural Networks and Deep Learning (Charu C. Aggarwall)\n",
    "    - Deep Learning (Ian Goodfellow, Yoshua Bengio & Aaron Courville)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exam\n",
    "\n",
    "-  15.07. (?)\n",
    "-  60min (?) or oral? If not $\\to$ don't forget your calculator\n",
    "-  Theoretical (I want you to understand the idea behind NN)\n",
    "-  Mathematical\n",
    "-  Coding (Pseudocode) - presumably, but not settled yet\n",
    "-  Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Structure (formal)\n",
    "\n",
    "0. Appetizer\n",
    "\n",
    "I. Initialization\n",
    "\n",
    "II. Model\n",
    "\n",
    "III. Loss (function)\n",
    "\n",
    "IV. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Structure (circle-ish)\n",
    "\n",
    "1. Recognize handwritten digits (coding)\n",
    "\n",
    "\n",
    "2. Understand the theory behind the code\n",
    "\n",
    "\n",
    "3. Extend the theory\n",
    "\n",
    "\n",
    "4. Improve the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Timeline\n",
    "\n",
    "1. Today: Appetizer\n",
    "\n",
    "\n",
    "2. First 3-4 Weeks: Understand the appetizer\n",
    "\n",
    "\n",
    "3. Last 6-7 Weeks: Dive into Neural Networks\n",
    "\n",
    "\n",
    "4. Week 11: Off\n",
    "\n",
    "\n",
    "5. Week 12: Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 0. Appetizer\n",
    "\n",
    "Recognize handwritten digits using a NN in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tensor\n",
    "\n",
    "-  complex mathematical map\n",
    "-  what we have to know about them:\n",
    "    - ***type***: tf.float32, tf.int64, tf.string,...\n",
    "    - ***rank***: rank 0: Scalar. rank 1: Vector. rank 2: Matrix. rank 3: 3-Tensor (Cube)...\n",
    "    - ***shape***: Number of elements in each dimension\n",
    "        - scalar has shape ( )\n",
    "        - vector has shape (N0)\n",
    "        - matrix has shape (N0,N1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why Tensors and not matrices?\n",
    "\n",
    "Because we don't have to define the shape of a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c388e7809045>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "55000\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## Getting started & Data Set ##\n",
    "################################\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "#one_hot=TRUE: Conduct one-hot-encoding, i.e. the digit \"1\" [integer encoding] \n",
    "#              will be represented as (0,1,0,0,0,0,0,0,0,0).\n",
    "#              28x28 pixels are flattened into a 784 vector\n",
    "#              Grayscale of each pixel between 0 and 255 (black 255)\n",
    "\n",
    "print(mnist.train.num_examples) # #55 000 train data\n",
    "print(mnist.validation.num_examples) # #5000 validation data\n",
    "print(mnist.test.num_examples) # #10 000 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "## How does the data look like? ##\n",
    "##################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i=800\n",
    "\n",
    "dig = np.argmax(mnist.train.labels[i,:])\n",
    "#argmax due to one-hot encoding.\n",
    "#compare to using:\n",
    "#dig = mnist.train.labels[i,:]\n",
    "\n",
    "img = np.reshape(mnist.train.images[i,:], [28,28])\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show()\n",
    "print(dig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "####################\n",
    "## Architecture I ##\n",
    "####################\n",
    "\n",
    "## Single Layer NN\n",
    "n_input = 784  # input layer (28x28 pixels)\n",
    "n_output = 10  # output layer (0-9 digits)\n",
    "\n",
    "#Define 3 tensors as placeholders (tensors that we'll feed with values later)\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])   #None x 784\n",
    "Y = tf.placeholder(\"float\", [None, n_output])  #None x 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## Hyperparameters ##\n",
    "#####################\n",
    "\n",
    "learning_rate = 1e-4\n",
    "n_iterations = 1000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## Architecture II & Getting Started ##\n",
    "#######################################\n",
    "\n",
    "# Initial values for Weights and Bias\n",
    "\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.truncated_normal(shape = [n_input, n_output], stddev=0.1)),\n",
    "}\n",
    "\n",
    "#weights are variables since they will be updated\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, shape = [n_output])),\n",
    "}\n",
    "\n",
    "\n",
    "layer = tf.add(tf.matmul(X, weights['w1']) , biases['b1']) #using the identity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-2ac9569e9397>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Loss Function and Optimization ##\n",
    "####################################\n",
    "\n",
    "cross_entropy = tf.reduce_mean(   \n",
    "    tf.nn.softmax_cross_entropy_with_logits(  #use cross_entropy norm\n",
    "        labels=Y, logits = layer\n",
    "        ))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "                      #use the Adam Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## Define Accuracy ##\n",
    "#####################\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t Loss = 2.570116 \t Minibatch-Accuracy = 0.078125\n",
      "Iteration 100 \t Loss = 2.164329 \t Minibatch-Accuracy = 0.1953125\n",
      "Iteration 200 \t Loss = 1.8196056 \t Minibatch-Accuracy = 0.40625\n",
      "Iteration 300 \t Loss = 1.5178676 \t Minibatch-Accuracy = 0.625\n",
      "Iteration 400 \t Loss = 1.4307848 \t Minibatch-Accuracy = 0.6796875\n",
      "Iteration 500 \t Loss = 1.2642115 \t Minibatch-Accuracy = 0.6875\n",
      "Iteration 600 \t Loss = 1.1738114 \t Minibatch-Accuracy = 0.7109375\n",
      "Iteration 700 \t Loss = 1.0439711 \t Minibatch-Accuracy = 0.7734375\n",
      "Iteration 800 \t Loss = 0.96109724 \t Minibatch-Accuracy = 0.796875\n",
      "Iteration 900 \t Loss = 0.7684494 \t Minibatch-Accuracy = 0.875\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "## Run the NN ##\n",
    "################\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={\n",
    "        X: batch_x, Y: batch_y\n",
    "        })\n",
    "\n",
    "    # print loss and accuracy (per minibatch)\n",
    "    if i % 100 == 0:\n",
    "        minibatch_loss, minibatch_accuracy = sess.run(\n",
    "            [cross_entropy, accuracy],\n",
    "            feed_dict={X: batch_x, Y: batch_y}\n",
    "            )\n",
    "        print(\n",
    "            \"Iteration\",\n",
    "            str(i),\n",
    "            \"\\t Loss =\",\n",
    "            str(minibatch_loss),\n",
    "            \"\\t Minibatch-Accuracy =\",\n",
    "            str(minibatch_accuracy)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on test data: 0.8185\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "## Accuracy on test data ##\n",
    "###########################\n",
    "\n",
    "test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n",
    "print(\"\\nAccuracy on test data:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## Checking the performance manually ##\n",
    "#######################################\n",
    "\n",
    "test_digit = 22\n",
    "\n",
    "img = np.reshape(mnist.test.images[test_digit,:], [28,28])\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "#dig = np.argmax(mnist.test.labels[test_digit,:])\n",
    "#print(dig)\n",
    "\n",
    "prediction = sess.run(tf.argmax(layer, 1), feed_dict={X: mnist.test.images})\n",
    "print (\"Prediction:\", np.squeeze(prediction)[test_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
