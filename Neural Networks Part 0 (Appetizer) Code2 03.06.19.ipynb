{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c388e7809045>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "55000\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## Getting started & Data Set ##\n",
    "################################\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "#one_hot=TRUE: Conduct one-hot-encoding, i.e. the digit \"1\" [integer encoding] \n",
    "#              will be represented as (0,1,0,0,0,0,0,0,0,0).\n",
    "#              28x28 pixels are flattened into a 784 vector\n",
    "#              Grayscale of each pixel between 0 and 255 (black 255)\n",
    "\n",
    "print(mnist.train.num_examples) # #55 000 train data\n",
    "print(mnist.validation.num_examples) # #5000 validation data\n",
    "print(mnist.test.num_examples) # #10 000 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "## How does the data look like? ##\n",
    "##################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i=1\n",
    "\n",
    "dig = np.argmax(mnist.train.labels[i,:])\n",
    "#argmax due to one-hot encoding.\n",
    "#compare to using:\n",
    "#dig = mnist.train.labels[i,:]\n",
    "\n",
    "img = np.reshape(mnist.train.images[i,:], [28,28])\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show()\n",
    "print(dig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "####################\n",
    "## Architecture I ##\n",
    "####################\n",
    "\n",
    "## Five Layer NN\n",
    "n_input = 784  # input layer (28x28 pixels)\n",
    "n_1 = 512  # 1st hidden layer\n",
    "n_2 = 256  # 2nd hidden layer\n",
    "n_3 = 128  # 3rd hidden layer\n",
    "n_4 = 64   # 4th hidden layer\n",
    "n_output = 10  # output layer (0-9 digits)\n",
    "\n",
    "#Define 2 tensors as placeholders (tensors that we'll feed with values later)\n",
    "\n",
    "x     = tf.placeholder(\"float\", [None, n_input])   #None x 784\n",
    "ystar = tf.placeholder(\"float\", [None, n_output])  #None x 10\n",
    "\n",
    "#PREVIOUS: Ystar = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## Hyperparameters ##\n",
    "#####################\n",
    "\n",
    "learning_rate = 1e-4\n",
    "n_iterations = 1000\n",
    "batch_size = 128\n",
    "#n_iterations = 3500\n",
    "#batch_size = 4112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## Architecture II & Getting Started ##\n",
    "#######################################\n",
    "\n",
    "# Initial values for Weights\n",
    "\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.truncated_normal([n_input, n_1], stddev=0.1)),\n",
    "    'w2': tf.Variable(tf.truncated_normal([n_1, n_2], stddev=0.1)),\n",
    "    'w3': tf.Variable(tf.truncated_normal([n_2, n_3], stddev=0.1)),\n",
    "    'w4': tf.Variable(tf.truncated_normal([n_3, n_4], stddev=0.1)),\n",
    "    'w5': tf.Variable(tf.truncated_normal([n_4, n_output], stddev=0.1)),\n",
    "}\n",
    "\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, shape = [n_1])),\n",
    "    'b2': tf.Variable(tf.constant(0.1, shape = [n_2])),\n",
    "    'b3': tf.Variable(tf.constant(0.1, shape = [n_3])),\n",
    "    'b4': tf.Variable(tf.constant(0.1, shape = [n_4])),\n",
    "    'b5': tf.Variable(tf.constant(0.1, shape = [n_output])),\n",
    "}\n",
    "\n",
    "\n",
    "h_1 = tf.maximum(tf.add(tf.matmul(x, weights['w1']), biases['b1']), 0)     #ReLU\n",
    "h_2 = tf.maximum(tf.add(tf.matmul(h_1, weights['w2']), biases['b2']), 0)   #ReLU\n",
    "h_3 = tf.maximum(tf.add(tf.matmul(h_2, weights['w3']), biases['b3']), 0)   #ReLU\n",
    "h_4 = tf.maximum(tf.add(tf.matmul(h_3, weights['w4']), biases['b4']), 0)   #ReLU\n",
    "y   = tf.math.softmax(tf.matmul(h_4, weights['w5']) + biases['b5'])        #Softmax\n",
    "#PREVIOUS: y = output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "## Loss Function and Optimization ##\n",
    "####################################\n",
    "cross_entropy = -tf.reduce_mean(ystar * tf.log(y)) +0.00001   #don't use the python-function anymore\n",
    "                                                              #code it mathematically  \n",
    "    \n",
    "#cross_entropy = tf.reduce_mean(   \n",
    "#    tf.nn.softmax_cross_entropy_with_logits(  #use cross_entropy norm\n",
    "#        labels=ystar, logits = y\n",
    "#        ))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#                      #use the Adam Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## Define Accuracy ##\n",
    "#####################\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(ystar, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_loss =  [0.2451495, None, None, None, None, None, None, None, None, None]\n",
      "Iteration 0 \t Minibatch-Loss = 0.24306792 \t Minibatch-Accuracy = 0.1484375\n",
      "Iteration 0 \t Test-loss      = 0.2451495 \t Test-Accuracy      = 0.118\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, None, None, None, None, None, None, None, None]\n",
      "Iteration 100 \t Minibatch-Loss = 0.067842305 \t Minibatch-Accuracy = 0.8359375\n",
      "Iteration 100 \t Test-loss      = 0.07493487 \t Test-Accuracy      = 0.8236\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, 0.039112408, None, None, None, None, None, None, None]\n",
      "Iteration 200 \t Minibatch-Loss = 0.05362671 \t Minibatch-Accuracy = 0.8671875\n",
      "Iteration 200 \t Test-loss      = 0.039112408 \t Test-Accuracy      = 0.896\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, 0.039112408, 0.03102341, None, None, None, None, None, None]\n",
      "Iteration 300 \t Minibatch-Loss = 0.04733749 \t Minibatch-Accuracy = 0.8359375\n",
      "Iteration 300 \t Test-loss      = 0.03102341 \t Test-Accuracy      = 0.9159\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, 0.039112408, 0.03102341, 0.025777819, None, None, None, None, None]\n",
      "Iteration 400 \t Minibatch-Loss = 0.021025507 \t Minibatch-Accuracy = 0.9375\n",
      "Iteration 400 \t Test-loss      = 0.025777819 \t Test-Accuracy      = 0.9269\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, 0.039112408, 0.03102341, 0.025777819, 0.023072788, None, None, None, None]\n",
      "Iteration 500 \t Minibatch-Loss = 0.026274256 \t Minibatch-Accuracy = 0.90625\n",
      "Iteration 500 \t Test-loss      = 0.023072788 \t Test-Accuracy      = 0.9337\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, 0.039112408, 0.03102341, 0.025777819, 0.023072788, 0.021937154, None, None, None]\n",
      "Iteration 600 \t Minibatch-Loss = 0.02187069 \t Minibatch-Accuracy = 0.9609375\n",
      "Iteration 600 \t Test-loss      = 0.021937154 \t Test-Accuracy      = 0.9342\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, 0.039112408, 0.03102341, 0.025777819, 0.023072788, 0.021937154, 0.019488232, None, None]\n",
      "Iteration 700 \t Minibatch-Loss = 0.02252784 \t Minibatch-Accuracy = 0.9296875\n",
      "Iteration 700 \t Test-loss      = 0.019488232 \t Test-Accuracy      = 0.9436\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, 0.039112408, 0.03102341, 0.025777819, 0.023072788, 0.021937154, 0.019488232, 0.018675536, None]\n",
      "Iteration 800 \t Minibatch-Loss = 0.025841115 \t Minibatch-Accuracy = 0.9296875\n",
      "Iteration 800 \t Test-loss      = 0.018675536 \t Test-Accuracy      = 0.9455\n",
      "------------------------------------------------------------------------------\n",
      "t_loss =  [0.2451495, 0.07493487, 0.039112408, 0.03102341, 0.025777819, 0.023072788, 0.021937154, 0.019488232, 0.018675536, 0.018029014]\n",
      "Iteration 900 \t Minibatch-Loss = 0.019399352 \t Minibatch-Accuracy = 0.953125\n",
      "Iteration 900 \t Test-loss      = 0.018029014 \t Test-Accuracy      = 0.9464\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "## Run the NN ##\n",
    "################\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "t_loss = [None] * 10\n",
    "b_loss = [None] * 10\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={\n",
    "        x: batch_x, ystar: batch_y\n",
    "        })\n",
    "\n",
    "    # print loss and accuracy (per minibatch)\n",
    "    if i % 100 == 0:\n",
    "        minibatch_loss, minibatch_accuracy = sess.run(\n",
    "            [cross_entropy, accuracy],\n",
    "            feed_dict={x: batch_x, ystar: batch_y}\n",
    "            )\n",
    "        \n",
    "        test_accuracy = sess.run(accuracy,      feed_dict={x: mnist.test.images, ystar: mnist.test.labels})\n",
    "        test_loss     = sess.run(cross_entropy, feed_dict={x: mnist.test.images, ystar: mnist.test.labels}) \n",
    "        \n",
    "        j=int(i/100)\n",
    "        t_loss[j] = test_loss\n",
    "        b_loss[j] = minibatch_loss\n",
    "        \n",
    "        print(\n",
    "            \"Iteration\",\n",
    "            str(i),\n",
    "            \"\\t Minibatch-Loss =\",\n",
    "            str(minibatch_loss),\n",
    "            \"\\t Minibatch-Accuracy =\",\n",
    "            str(minibatch_accuracy))\n",
    "        print(\n",
    "            \"Iteration\",\n",
    "            str(i),\n",
    "            \"\\t Test-loss      =\",\n",
    "            str(test_loss),\n",
    "            \"\\t Test-Accuracy      =\",\n",
    "            str(test_accuracy)\n",
    "            )\n",
    "        print(\"------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## Accuracy on test data ##\n",
    "###########################\n",
    "\n",
    "test_accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images, ystar: mnist.test.labels})\n",
    "print(\"\\nAccuracy on test data:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## Checking the performance manually ##\n",
    "#######################################\n",
    "\n",
    "test_digit = 24\n",
    "\n",
    "img = np.reshape(mnist.test.images[test_digit,:], [28,28])\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "#dig = np.argmax(mnist.test.labels[test_digit,:])\n",
    "#print(dig)\n",
    "\n",
    "prediction = sess.run(tf.argmax(y, 1), feed_dict={x: mnist.test.images})\n",
    "print (\"Prediction:\", np.squeeze(prediction)[test_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 10)\n"
     ]
    }
   ],
   "source": [
    "p = range(1,10,1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
